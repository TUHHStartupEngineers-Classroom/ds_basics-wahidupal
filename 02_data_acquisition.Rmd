---
title: "02 Data Acqusition"
author: "Wahidur Rahman Upal"
date: "07-05-2021"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    collapsed: false
    number_sections: true
    toc_depth: 3
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

Get some data via an API. There are millions of providers, that offer API access for free and have good documentation about how to query their service. You just have to google them. You can use whatever service you want. For example, you can get data about your listening history (spotify), get data about flights (skyscanner) or just check the weather forecast. Print the data in a readable format, e.g. a table if you want, you could also plot it.



```{r}

library(httr)
library(glue)
library(tibble)
library(jsonlite)
library(tidyverse)
library(purrr)
library(stringr)
library(xml2)
wp_url <- "https://apify.com/covid-19" # Data Scraping 
wp <- xml2::read_html(wp_url)
data_frame <- rvest::html_table(wp)[[1]] %>% 
  tibble::as_tibble(.name_repair = "unique") # Columns Repairing
data_frame %>% dplyr::glimpse(45)
data_frame

```

When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You'll learn that all of these things and more can be customized in each R code block.




Scrape one of the competitor websites of canyon (either https://www.rosebikes.de/ or https://www.radon-bikes.de) and create a small database. The database should contain the model names and prices for at least one category. Use the selectorgadget to get a good understanding of the website structure, it is really helpful. After scraping your data, convert it to a readable format. Prices should be in a numeric format without any other letters or symbols. Also check if the prices are reasonable


```{r}
library(tidyverse) 
library(rvest)     
library(xopen)     
library(jsonlite)  
library(glue)      
library(stringi)   

url_home          <- "https://www.rosebikes.de/fahrr%C3%A4der/mtb"
# Open links directly from RStudio to inspect them

html_home         <- read_html(url_home) # Read in the HTML for the entire web page

# data scraping from the web page for  the bike models 
bike_model <- html_home %>% 
  
  html_nodes(css = ".catalog-category-bikes__title-text") %>% 
  html_text() %>%
  
  str_remove_all("\n") 

bike_model

# data scraping from the web page for  the bike prices

bike_price <- html_home %>%
  
  html_nodes(css = ".catalog-category-bikes__price-title") %>%
  html_text() %>%
  
  str_remove_all("\\.") %>%
  stringr::str_replace_all(pattern = "\nab ", replacement = "") %>%
  stringr::str_replace_all(pattern = "\n", replacement = "") 

bike_price

# merging the two tables into one

da2 <- tibble(bike_model, bike_price)

da2 <- da2 %>% mutate(bike_price = as.character(gsub("â‚¬", "", bike_price)))
da2$bike_price <- as.character(gsub(",","",da2$bike_price))
da2$bike_price <- as.character(gsub("ab","",da2$bike_price))
#d<-da2
da2


#write_rds(da2, "C:\\Users\\upal1\\Desktop\\DS basic project\\ds_basics-wahidupal\\Data Acquisition 2.R")

#write.csv(x=da2, file="C:\\Users\\upal1\\Desktop\\DS basic project\\ds_basics-wahidupal\\data_accuisition2.csv")
```